{'batch_size': 64,
 'client_lr': 0.001,
 'dataset': 'CIFAR10',
 'dynamic': False,
 'epochs': 80,
 'kv_factor': 1,
 'kv_refresh_rate': 0,
 'model': 'resnet18',
 'number_of_clients': 10,
 'offload_only': False,
 'p_epoch': 50,
 'personalize': False,
 'pool': False,
 'pretrained': True,
 'seed': 42,
 'server_lr': 0.001,
 'split': 2,
 'test_batch_size': 256,
 'use_key_value_store': True,
 'wandb': True,
 'wandb_name': None}
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client hbrp -> #train 500 #valid: 250 #test: 999
Client hbrp class distribution (proportions):
  Train: {0: 0.074, 1: 0.232, 2: 0.024, 3: 0.008, 4: 0.156, 5: 0.002, 6: 0.326, 7: 0.03, 8: 0.056, 9: 0.092}
  Test: {0: 0.076, 1: 0.232, 2: 0.024, 3: 0.008, 4: 0.156, 5: 0.004, 6: 0.324, 7: 0.028, 8: 0.056, 9: 0.092}
  Main Test: {0: 0.07407407407407407, 1: 0.23223223223223224, 2: 0.025025025025025027, 3: 0.008008008008008008, 4: 0.15615615615615616, 5: 0.003003003003003003, 6: 0.3253253253253253, 7: 0.02902902902902903, 8: 0.056056056056056056, 9: 0.09109109109109109}
Client hbrp class distribution:
  Train: Counter({6: 163, 1: 116, 4: 78, 9: 46, 0: 37, 8: 28, 7: 15, 2: 12, 3: 4, 5: 1})
  Test: Counter({6: 81, 1: 58, 4: 39, 9: 23, 0: 19, 8: 14, 7: 7, 2: 6, 3: 2, 5: 1})
  Main Test: Counter({6: 325, 1: 232, 4: 156, 9: 91, 0: 74, 8: 56, 7: 29, 2: 25, 3: 8, 5: 3})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client oig9 -> #train 501 #valid: 249 #test: 1001
Client oig9 class distribution (proportions):
  Train: {0: 0.01996007984031936, 1: 0.04590818363273453, 2: 0.005988023952095809, 3: 0.08582834331337326, 4: 0.007984031936127744, 5: 0.14770459081836326, 6: 0.36127744510978044, 7: 0.24151696606786427, 8: 0.05189620758483034, 9: 0.031936127744510975}
  Test: {0: 0.020080321285140562, 1: 0.04417670682730924, 2: 0.004016064257028112, 3: 0.08835341365461848, 4: 0.008032128514056224, 5: 0.14859437751004015, 6: 0.3614457831325301, 7: 0.24096385542168675, 8: 0.05220883534136546, 9: 0.0321285140562249}
  Main Test: {0: 0.01998001998001998, 1: 0.04495504495504495, 2: 0.005994005994005994, 3: 0.08591408591408592, 4: 0.006993006993006993, 5: 0.14785214785214784, 6: 0.36163836163836166, 7: 0.24175824175824176, 8: 0.052947052947052944, 9: 0.03196803196803197}
Client oig9 class distribution:
  Train: Counter({6: 181, 7: 121, 5: 74, 3: 43, 8: 26, 1: 23, 9: 16, 0: 10, 4: 4, 2: 3})
  Test: Counter({6: 90, 7: 60, 5: 37, 3: 22, 8: 13, 1: 11, 9: 8, 0: 5, 4: 2, 2: 1})
  Main Test: Counter({6: 362, 7: 242, 5: 148, 3: 86, 8: 53, 1: 45, 9: 32, 0: 20, 4: 7, 2: 6})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client f2cb -> #train 501 #valid: 250 #test: 999
Client f2cb class distribution (proportions):
  Train: {0: 0.017964071856287425, 1: 0.03592814371257485, 2: 0.07584830339321358, 3: 0.11776447105788423, 4: 0.14570858283433133, 5: 0.20159680638722555, 6: 0.013972055888223553, 7: 0.28542914171656686, 8: 0.00998003992015968, 9: 0.09580838323353294}
  Test: {0: 0.02, 1: 0.036, 2: 0.076, 3: 0.116, 4: 0.148, 5: 0.204, 6: 0.012, 7: 0.284, 8: 0.008, 9: 0.096}
  Main Test: {0: 0.01901901901901902, 1: 0.036036036036036036, 2: 0.07607607607607608, 3: 0.11711711711711711, 4: 0.14614614614614616, 5: 0.2022022022022022, 6: 0.013013013013013013, 7: 0.2862862862862863, 8: 0.009009009009009009, 9: 0.09509509509509509}
Client f2cb class distribution:
  Train: Counter({7: 143, 5: 101, 4: 73, 3: 59, 9: 48, 2: 38, 1: 18, 0: 9, 6: 7, 8: 5})
  Test: Counter({7: 71, 5: 51, 4: 37, 3: 29, 9: 24, 2: 19, 1: 9, 0: 5, 6: 3, 8: 2})
  Main Test: Counter({7: 286, 5: 202, 4: 146, 3: 117, 9: 95, 2: 76, 1: 36, 0: 19, 6: 13, 8: 9})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client fno7 -> #train 498 #valid: 251 #test: 999
Client fno7 class distribution (proportions):
  Train: {0: 0.0642570281124498, 1: 0.3152610441767068, 2: 0.024096385542168676, 3: 0.06827309236947791, 4: 0.20080321285140562, 5: 0.05823293172690763, 6: 0.17269076305220885, 7: 0.04819277108433735, 8: 0.002008032128514056, 9: 0.04618473895582329}
  Test: {0: 0.06374501992031872, 1: 0.3147410358565737, 2: 0.02390438247011952, 3: 0.06772908366533864, 4: 0.199203187250996, 5: 0.05976095617529881, 6: 0.17131474103585656, 7: 0.04780876494023904, 8: 0.00398406374501992, 9: 0.04780876494023904}
  Main Test: {0: 0.06306306306306306, 1: 0.31431431431431434, 2: 0.024024024024024024, 3: 0.06806806806806807, 4: 0.2012012012012012, 5: 0.05905905905905906, 6: 0.17217217217217218, 7: 0.04904904904904905, 8: 0.003003003003003003, 9: 0.04604604604604605}
Client fno7 class distribution:
  Train: Counter({1: 157, 4: 100, 6: 86, 3: 34, 0: 32, 5: 29, 7: 24, 9: 23, 2: 12, 8: 1})
  Test: Counter({1: 79, 4: 50, 6: 43, 3: 17, 0: 16, 5: 15, 7: 12, 9: 12, 2: 6, 8: 1})
  Main Test: Counter({1: 314, 4: 201, 6: 172, 3: 68, 0: 63, 5: 59, 7: 49, 9: 46, 2: 24, 8: 3})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client b0m9 -> #train 499 #valid: 250 #test: 999
Client b0m9 class distribution (proportions):
  Train: {0: 0.05811623246492986, 1: 0.11222444889779559, 2: 0.1462925851703407, 3: 0.12024048096192384, 4: 0.06813627254509018, 5: 0.06412825651302605, 6: 0.06212424849699399, 7: 0.14829659318637275, 8: 0.0781563126252505, 9: 0.14228456913827656}
  Test: {0: 0.06, 1: 0.112, 2: 0.144, 3: 0.12, 4: 0.068, 5: 0.064, 6: 0.064, 7: 0.148, 8: 0.08, 9: 0.14}
  Main Test: {0: 0.05805805805805806, 1: 0.11311311311311312, 2: 0.14514514514514515, 3: 0.11911911911911911, 4: 0.06906906906906907, 5: 0.06506506506506507, 6: 0.062062062062062065, 7: 0.14914914914914915, 8: 0.07807807807807808, 9: 0.14114114114114115}
Client b0m9 class distribution:
  Train: Counter({7: 74, 2: 73, 9: 71, 3: 60, 1: 56, 8: 39, 4: 34, 5: 32, 6: 31, 0: 29})
  Test: Counter({7: 37, 2: 36, 9: 35, 3: 30, 1: 28, 8: 20, 4: 17, 5: 16, 6: 16, 0: 15})
  Main Test: Counter({7: 149, 2: 145, 9: 141, 3: 119, 1: 113, 8: 78, 4: 69, 5: 65, 6: 62, 0: 58})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client 1o3r -> #train 499 #valid: 250 #test: 1000
Client 1o3r class distribution (proportions):
  Train: {0: 0.004008016032064128, 1: 0.004008016032064128, 2: 0.014028056112224449, 3: 0.006012024048096192, 4: 0.17034068136272545, 5: 0.3026052104208417, 6: 0.1523046092184369, 7: 0.17234468937875752, 8: 0.06212424849699399, 9: 0.11222444889779559}
  Test: {0: 0.004, 1: 0.004, 2: 0.016, 3: 0.008, 4: 0.168, 5: 0.304, 6: 0.152, 7: 0.172, 8: 0.06, 9: 0.112}
  Main Test: {0: 0.005, 1: 0.004, 2: 0.014, 3: 0.007, 4: 0.17, 5: 0.303, 6: 0.152, 7: 0.172, 8: 0.061, 9: 0.112}
Client 1o3r class distribution:
  Train: Counter({5: 151, 7: 86, 4: 85, 6: 76, 9: 56, 8: 31, 2: 7, 3: 3, 0: 2, 1: 2})
  Test: Counter({5: 76, 7: 43, 4: 42, 6: 38, 9: 28, 8: 15, 2: 4, 3: 2, 0: 1, 1: 1})
  Main Test: Counter({5: 303, 7: 172, 4: 170, 6: 152, 9: 112, 8: 61, 2: 14, 3: 7, 0: 5, 1: 4})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client ak2v -> #train 500 #valid: 249 #test: 1000
Client ak2v class distribution (proportions):
  Train: {1: 0.002, 2: 0.012, 3: 0.302, 4: 0.02, 5: 0.474, 6: 0.002, 7: 0.07, 8: 0.068, 9: 0.05}
  Test: {1: 0.004016064257028112, 2: 0.012048192771084338, 3: 0.30522088353413657, 4: 0.020080321285140562, 5: 0.4738955823293173, 7: 0.06827309236947791, 8: 0.06827309236947791, 9: 0.04819277108433735}
  Main Test: {1: 0.003, 2: 0.012, 3: 0.303, 4: 0.021, 5: 0.473, 6: 0.001, 7: 0.069, 8: 0.068, 9: 0.05}
Client ak2v class distribution:
  Train: Counter({5: 237, 3: 151, 7: 35, 8: 34, 9: 25, 4: 10, 2: 6, 1: 1, 6: 1})
  Test: Counter({5: 118, 3: 76, 7: 17, 8: 17, 9: 12, 4: 5, 2: 3, 1: 1})
  Main Test: Counter({5: 473, 3: 303, 7: 69, 8: 68, 9: 50, 4: 21, 2: 12, 1: 3, 6: 1})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client rjnv -> #train 500 #valid: 250 #test: 1000
Client rjnv class distribution (proportions):
  Train: {0: 0.03, 1: 0.192, 2: 0.058, 3: 0.032, 4: 0.17, 5: 0.002, 6: 0.056, 7: 0.204, 8: 0.118, 9: 0.138}
  Test: {0: 0.032, 1: 0.192, 2: 0.06, 3: 0.032, 4: 0.168, 5: 0.004, 6: 0.056, 7: 0.204, 8: 0.116, 9: 0.136}
  Main Test: {0: 0.03, 1: 0.193, 2: 0.058, 3: 0.032, 4: 0.17, 5: 0.003, 6: 0.056, 7: 0.204, 8: 0.117, 9: 0.137}
Client rjnv class distribution:
  Train: Counter({7: 102, 1: 96, 4: 85, 9: 69, 8: 59, 2: 29, 6: 28, 3: 16, 0: 15, 5: 1})
  Test: Counter({7: 51, 1: 48, 4: 42, 9: 34, 8: 29, 2: 15, 6: 14, 0: 8, 3: 8, 5: 1})
  Main Test: Counter({7: 204, 1: 193, 4: 170, 9: 137, 8: 117, 2: 58, 6: 56, 3: 32, 0: 30, 5: 3})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client gfyw -> #train 500 #valid: 251 #test: 1000
Client gfyw class distribution (proportions):
  Train: {0: 0.002, 1: 0.028, 2: 0.256, 4: 0.016, 5: 0.076, 6: 0.196, 7: 0.106, 8: 0.136, 9: 0.184}
  Test: {0: 0.00398406374501992, 1: 0.027888446215139442, 2: 0.2549800796812749, 4: 0.01593625498007968, 5: 0.07569721115537849, 6: 0.1952191235059761, 7: 0.10756972111553785, 8: 0.13545816733067728, 9: 0.18326693227091634}
  Main Test: {0: 0.002, 1: 0.027, 2: 0.256, 3: 0.001, 4: 0.016, 5: 0.076, 6: 0.197, 7: 0.106, 8: 0.136, 9: 0.183}
Client gfyw class distribution:
  Train: Counter({2: 128, 6: 98, 9: 92, 8: 68, 7: 53, 5: 38, 1: 14, 4: 8, 0: 1})
  Test: Counter({2: 64, 6: 49, 9: 46, 8: 34, 7: 27, 5: 19, 1: 7, 4: 4, 0: 1})
  Main Test: Counter({2: 256, 6: 197, 9: 183, 8: 136, 7: 106, 5: 76, 1: 27, 4: 16, 0: 2, 3: 1})
Files already downloaded and verified
Files already downloaded and verified
Training
Validation
Testing
client wqc4 -> #train 501 #valid: 249 #test: 1000
Client wqc4 class distribution (proportions):
  Train: {0: 0.0499001996007984, 1: 0.05788423153692615, 2: 0.005988023952095809, 3: 0.1277445109780439, 4: 0.3193612774451098, 5: 0.09181636726546906, 6: 0.005988023952095809, 7: 0.03592814371257485, 8: 0.19560878243512975, 9: 0.10978043912175649}
  Test: {0: 0.04819277108433735, 1: 0.060240963855421686, 2: 0.004016064257028112, 3: 0.1285140562248996, 4: 0.321285140562249, 5: 0.09236947791164658, 6: 0.004016064257028112, 7: 0.03614457831325301, 8: 0.19678714859437751, 9: 0.10843373493975904}
  Main Test: {0: 0.05, 1: 0.059, 2: 0.006, 3: 0.127, 4: 0.319, 5: 0.092, 6: 0.005, 7: 0.037, 8: 0.196, 9: 0.109}
Client wqc4 class distribution:
  Train: Counter({4: 160, 8: 98, 3: 64, 9: 55, 5: 46, 1: 29, 0: 25, 7: 18, 2: 3, 6: 3})
  Test: Counter({4: 80, 8: 49, 3: 32, 9: 27, 5: 23, 1: 15, 0: 12, 7: 9, 2: 1, 6: 1})
  Main Test: Counter({4: 319, 8: 196, 3: 127, 9: 109, 5: 92, 1: 59, 0: 50, 7: 37, 2: 6, 6: 5})
generated 10 clients with data
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=512, out_features=1000, bias=True)
)
Front Model:
front(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): ReLU(inplace=True)
  (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
)

Center Front Model:
center_front(
  (l1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (l2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Center Back Model:
center_back(
  (l3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (l4_0): BasicBlock(
    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (downsample): Sequential(
      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Back Model:
back(
  (l4_1): Sequential(
    (1): BasicBlock(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (l5): AdaptiveAvgPool2d(output_size=(1, 1))
  (fl): Flatten(start_dim=1, end_dim=-1)
  (fc): Linear(in_features=512, out_features=10, bias=True)
)
Initialized client-side model splits front & back and their optimizers
Initialized server-side model splits center_front, center_back, and center_back optimizer
Directory created at saved_models/CIFAR10/key_value_mode/model_split2
generating training samples in key-value store...
Training Set Key Value Store Created for Client hbrp
Training Set Key Value Store Length is : 500
Training Set Key Value Store Created for Client oig9
Training Set Key Value Store Length is : 501
Training Set Key Value Store Created for Client f2cb
Training Set Key Value Store Length is : 501
Training Set Key Value Store Created for Client fno7
Training Set Key Value Store Length is : 498
Training Set Key Value Store Created for Client b0m9
Training Set Key Value Store Length is : 499
Training Set Key Value Store Created for Client 1o3r
Training Set Key Value Store Length is : 499
Training Set Key Value Store Created for Client ak2v
Training Set Key Value Store Length is : 500
Training Set Key Value Store Created for Client rjnv
Training Set Key Value Store Length is : 500
Training Set Key Value Store Created for Client gfyw
Training Set Key Value Store Length is : 500
Training Set Key Value Store Created for Client wqc4
Training Set Key Value Store Length is : 501
generating testing samples in key-value store...
Validation Set Key Value Store Created for Client hbrp
Validation Set Key Value Store Length is : 250
Validation Set Key Value Store Created for Client oig9
Validation Set Key Value Store Length is : 249
Validation Set Key Value Store Created for Client f2cb
Validation Set Key Value Store Length is : 250
Validation Set Key Value Store Created for Client fno7
Validation Set Key Value Store Length is : 251
Validation Set Key Value Store Created for Client b0m9
Validation Set Key Value Store Length is : 250
Validation Set Key Value Store Created for Client 1o3r
Validation Set Key Value Store Length is : 250
Validation Set Key Value Store Created for Client ak2v
Validation Set Key Value Store Length is : 249
Validation Set Key Value Store Created for Client rjnv
Validation Set Key Value Store Length is : 250
Validation Set Key Value Store Created for Client gfyw
Validation Set Key Value Store Length is : 251
Validation Set Key Value Store Created for Client wqc4
Validation Set Key Value Store Length is : 249
-------------------------

commence training...




Generalisation Phase Training 0..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.6420273184776306
avg train accuracy all clients:  0.6391266138172986
Merging model weights at epoch 0
Created list to store f1 score for test data.
validation f1:  tensor(0.6454)
validation acc:  0.6450882158114529
0
MAX Validation Accuracy Score: 0.6450882158114529 @ epoch 0
True
Model improved and saved.
Save Model at epoch 0
Save Best Model for Generalisation Phase


Generalisation Phase Training 1..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.8421958088874817
avg train accuracy all clients:  0.8415766463065852
Merging model weights at epoch 1
Created list to store f1 score for test data.
validation f1:  tensor(0.8422)
validation acc:  0.8423010864173828
0.6450882158114529
MAX Validation Accuracy Score: 0.8423010864173828 @ epoch 1
True
Model improved and saved.
Save Model at epoch 1
Save Best Model for Generalisation Phase


Generalisation Phase Training 2..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.9391952753067017
avg train accuracy all clients:  0.9385933836651009
Merging model weights at epoch 2
Created list to store f1 score for test data.
validation f1:  tensor(0.8762)
validation acc:  0.8759045680730893
0.8423010864173828
MAX Validation Accuracy Score: 0.8759045680730893 @ epoch 2
True
Model improved and saved.
Save Model at epoch 2
Save Best Model for Generalisation Phase


Generalisation Phase Training 3..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.9728218913078308
avg train accuracy all clients:  0.972602323112907
Merging model weights at epoch 3
Created list to store f1 score for test data.
validation f1:  tensor(0.8924)
validation acc:  0.892338315813053
0.8759045680730893
MAX Validation Accuracy Score: 0.892338315813053 @ epoch 3
True
Model improved and saved.
Save Model at epoch 3
Save Best Model for Generalisation Phase


Generalisation Phase Training 4..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.9850705862045288
avg train accuracy all clients:  0.9848011559371539
Merging model weights at epoch 4
Created list to store f1 score for test data.
validation f1:  tensor(0.8966)
validation acc:  0.8967303348853581
0.892338315813053
MAX Validation Accuracy Score: 0.8967303348853581 @ epoch 4
True
Model improved and saved.
Save Model at epoch 4
Save Best Model for Generalisation Phase


Generalisation Phase Training 5..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.9889364242553711
avg train accuracy all clients:  0.9888047663901498
Merging model weights at epoch 5
Created list to store f1 score for test data.
validation f1:  tensor(0.8923)
validation acc:  0.8927206963311413
False


Generalisation Phase Training 6..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.9941104054450989
avg train accuracy all clients:  0.9941991855871037
Merging model weights at epoch 6
Created list to store f1 score for test data.
validation f1:  tensor(0.8943)
validation acc:  0.8939158898542378
False


Generalisation Phase Training 7..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.997851550579071
avg train accuracy all clients:  0.9977975919807293
Merging model weights at epoch 7
Created list to store f1 score for test data.
validation f1:  tensor(0.9030)
validation acc:  0.9027159538552617
0.8967303348853581
MAX Validation Accuracy Score: 0.9027159538552617 @ epoch 7
True
Model improved and saved.
Save Model at epoch 7
Save Best Model for Generalisation Phase


Generalisation Phase Training 8..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.9983876943588257
avg train accuracy all clients:  0.9983979927823325
Merging model weights at epoch 8
Created list to store f1 score for test data.
validation f1:  tensor(0.8998)
validation acc:  0.8995094769516312
False


Generalisation Phase Training 9..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.9975565075874329
avg train accuracy all clients:  0.9975955847437848
Merging model weights at epoch 9
Created list to store f1 score for test data.
validation f1:  tensor(0.8947)
validation acc:  0.894722315557049
False


Generalisation Phase Training 10..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.99907386302948
avg train accuracy all clients:  0.9991983935742972
Merging model weights at epoch 10
Created list to store f1 score for test data.
validation f1:  tensor(0.9074)
validation acc:  0.9071159410550568
0.9027159538552617
MAX Validation Accuracy Score: 0.9071159410550568 @ epoch 10
True
Model improved and saved.
Save Model at epoch 10
Save Best Model for Generalisation Phase


Generalisation Phase Training 11..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  0.9996093511581421
avg train accuracy all clients:  0.9995983935742971
Merging model weights at epoch 11
Created list to store f1 score for test data.
validation f1:  tensor(0.9011)
validation acc:  0.9015015088241413
False


Generalisation Phase Training 12..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  1.0
avg train accuracy all clients:  1.0
Merging model weights at epoch 12
Created list to store f1 score for test data.
validation f1:  tensor(0.9008)
validation acc:  0.9007127154034464
False


Generalisation Phase Training 13..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  1.0
avg train accuracy all clients:  1.0
Merging model weights at epoch 13
Created list to store f1 score for test data.
validation f1:  tensor(0.8997)
validation acc:  0.8995126770028319
False


Generalisation Phase Training 14..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  1.0
avg train accuracy all clients:  1.0
Merging model weights at epoch 14
Created list to store f1 score for test data.
validation f1:  tensor(0.9029)
validation acc:  0.9035159282548519
False


Generalisation Phase Training 15..........................................................................................
Created list to store f1 score for train data.
avg train f1 all clients:  1.0
avg train accuracy all clients:  1.0
Merging model weights at epoch 15
Created list to store f1 score for test data.
validation f1:  tensor(0.9026)
validation acc:  0.9023159154546472
False
Early stopping at epoch 16
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.908171960971961
Personalization Started
Training Set Key Value Store Created for Client hbrp
Training Set Key Value Store Length is : 500
Training Set Key Value Store Created for Client oig9
Training Set Key Value Store Length is : 501
Training Set Key Value Store Created for Client f2cb
Training Set Key Value Store Length is : 501
Training Set Key Value Store Created for Client fno7
Training Set Key Value Store Length is : 498
Training Set Key Value Store Created for Client b0m9
Training Set Key Value Store Length is : 499
Training Set Key Value Store Created for Client 1o3r
Training Set Key Value Store Length is : 499
Training Set Key Value Store Created for Client ak2v
Training Set Key Value Store Length is : 500
Training Set Key Value Store Created for Client rjnv
Training Set Key Value Store Length is : 500
Training Set Key Value Store Created for Client gfyw
Training Set Key Value Store Length is : 500
Training Set Key Value Store Created for Client wqc4
Training Set Key Value Store Length is : 501
Validation Set Key Value Store Created for Client hbrp
Validation Set Key Value Store Length is : 750
Validation Set Key Value Store Created for Client oig9
Validation Set Key Value Store Length is : 750
Validation Set Key Value Store Created for Client f2cb
Validation Set Key Value Store Length is : 751
Validation Set Key Value Store Created for Client fno7
Validation Set Key Value Store Length is : 749
Validation Set Key Value Store Created for Client b0m9
Validation Set Key Value Store Length is : 749
Validation Set Key Value Store Created for Client 1o3r
Validation Set Key Value Store Length is : 749
Validation Set Key Value Store Created for Client ak2v
Validation Set Key Value Store Length is : 749
Validation Set Key Value Store Created for Client rjnv
Validation Set Key Value Store Length is : 750
Validation Set Key Value Store Created for Client gfyw
Validation Set Key Value Store Length is : 751
Validation Set Key Value Store Created for Client wqc4
Validation Set Key Value Store Length is : 750
 

 Personalisation Phase Training 16.........................................................................................
avg train f1 all clients:  1.225000023841858
avg train accuracy all clients:  1.0
validation f1:  tensor(1.2297)
validation acc:  0.913922443559097
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9172757627757628
 

 Personalisation Phase Training 17.........................................................................................
avg train f1 all clients:  1.2631250619888306
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3267)
validation acc:  0.9187209267348277
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9199763625763625
 

 Personalisation Phase Training 18.........................................................................................
avg train f1 all clients:  1.268890619277954
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3526)
validation acc:  0.9191241267860285
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9218762634762634
 

 Personalisation Phase Training 19.........................................................................................
avg train f1 all clients:  1.2697112560272217
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3604)
validation acc:  0.9203225075601209
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.922676063076063
 

 Personalisation Phase Training 20.........................................................................................
avg train f1 all clients:  1.2698239088058472
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3622)
validation acc:  0.919922507560121
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9208753625753626
 

 Personalisation Phase Training 21.........................................................................................
avg train f1 all clients:  1.2698390483856201
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3622)
validation acc:  0.9195176882830125
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9213755627755628
 

 Personalisation Phase Training 22.........................................................................................
avg train f1 all clients:  1.2698408365249634
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3602)
validation acc:  0.917514462631402
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9221757631757631
 

 Personalisation Phase Training 23.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3589)
validation acc:  0.9171144626314021
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9217759631759632
 

 Personalisation Phase Training 24.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3597)
validation acc:  0.9183208755340087
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9215759631759634
 

 Personalisation Phase Training 25.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3610)
validation acc:  0.9191192819085104
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9213758630758632
 

 Personalisation Phase Training 26.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3609)
validation acc:  0.9187192819085105
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9216760632760632
 

 Personalisation Phase Training 27.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3609)
validation acc:  0.9187192819085105
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9214759631759633
 

 Personalisation Phase Training 28.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3610)
validation acc:  0.9187192819085105
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9215759631759631
 

 Personalisation Phase Training 29.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3608)
validation acc:  0.9187192819085105
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9215759631759631
 

 Personalisation Phase Training 30.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3608)
validation acc:  0.9187192819085105
RUNNING INFERENCE from the best models on test dataset
Average inference score: 0.9217758632758632
 

 Personalisation Phase Training 31.........................................................................................
avg train f1 all clients:  1.269840955734253
avg train accuracy all clients:  1.0
validation f1:  tensor(1.3609)
validation acc:  0.9187192819085105
RUNNING INFERENCE from the best models on test dataset
